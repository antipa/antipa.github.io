<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async="" src="./antipa_files/js"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-144711474-1');
    </script>
<!-- Spell Check
    <script>
    javascript:document.designMode=document.designMode==='off'?'on':'off';void(0)
    </script>
-->

    
    
    
  <!-- Global site tag (gtag.js) - Google Analytics -->
<!--
  <script async="" src="./antipa_files/js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-135686194-1');
  </script>
-->
  
<!--  <meta name="viewport" content="“width=1280”">-->
  <meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
  <meta name="viewport" content="width=device-width">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
       
    /* Color scheme stolen from Sergey Karayev */
    .image { 
        position: relative; 
        width: 100%; /* for IE 6 */
    }

    h2 { 
        position: relative; 
        top: 5px; 
        left: 5px; 
        width: 100%; 
    }
   h3 { 
        position: absolute; 
        bottom: 20px; 
        left: 50px; 
        width: 100%; 
    }
    h4 {
        position: absolute; 
        top: -40px; 
        left: 5px; 
        width: 100%;
    }
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    .p{
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 18px
    }

  @media screen and (max-width: 600px) {
        p {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 32px;
        }
    }
/*
          @media screen and (min-width: 600px) {
        p {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 18px;
        }
    }
*/
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 100%
    }
    @media screen and (max-width: 600px) {
        a {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 32px;
        }
    }
      
    
      
    
    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 100%;
    }
    @media screen and (max-width: 600px) {
        strong {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 32px;
        }
    }
      
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 120%;
      font-weight: 700
    }
   @media screen and (max-width: 600px) {
        heading {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 38px;
        }
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 120%;
      font-weight: 700
    }
  @media screen and (max-width: 600px) {
        papertitle {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 38px;
        }
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 250%;
    }
    
    .one {
      
      position: relative;
    }
    
    .two {
    
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }
    
    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .content{
        word-wrap:break-word; /*old browsers*/
        overflow-wrap:break-word;
    }

    table{
        width:70%; /*must be set (to any value)*/
    }

    .overflow-wrap-hack{
        max-width:600px;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }
    * {
    box-sizing: border-box;
    }

    /* Create two equal columns that floats next to each other */
    .container{
        width: 100%;
        
        
    }
    .column {
      float: left;
      width: 50%;
      padding: 10px;
     
    }
    .column_twothirds {
      float: left;
      width: 66%;
      padding: 10px;
      
    }
    .column_onefifth {
      float: left;
      width: 20%;
      padding: 10px;
      
    }
  .column_fourfifths {
      float: left;
      width: 80%;
      padding: 10px;
      
    }
    .column_right{
      float: right;
      width: 66%;
      padding: 10px;
      
    }
    .column_full {
      float: center;
      width: 100%;
      padding: 10px;
    
      
    }
    .column_onethird {
      float: left;
      width: 33%;
      padding: 10px;
      
    }

    /* Clear floats after the columns */
    .row:after {
      content: "";
      display: table;
      clear: both;
    }

    /* Responsive layout - makes the two columns stack on top of each other instead of next to each other */
    @media screen and (max-width: 1000px) {
      .column {
        width: 100%;
      }
    }
      
      
      
  </style>
  <link rel="icon" type="image/png" href="https://people.eecs.berkeley.edu/~kellman/seal_icon.png">
    
  <title>Nick Antipa</title>
  
  <link href="./antipa_files/css" rel="stylesheet" type="text/css">
</head>

<body>
<div class="container">


<!--   <nav align="center">
    <ul>
      <a href="#home"><a href="index.html">home</a></a> &nbsp&nbsp&nbsp&nbsp
      <a href="#publications"><a href="pubs.html">publications</a></a>
    </ul>
  </nav>
<hr /> -->
<table width="62.5%" border="0" align="center" cellspacing="50px" cellpadding="0">
<tbody>
<tr>
<!--<td style="word-break:break-all">-->
<td class="overflow-wrap-hack">
<table width="62.5%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
<!--        <tr>-->
        <div class="row">
<!--            <td width="67%" valign="middle" style="word-break:break-all">-->
            <div class="column_fourfifths">
                <p align="center">
                    <name>Nick Antipa</name>
                </p>

<!--
                <p  align="center">
                    <img src="./antipa_files/UC-Berkeley-wordmark_blue.svg" style="height:40px;"><font style="font-size: 250%">&nbsp;|&nbsp;</font>
                    <img src="./antipa_files/UR-logo.svg" style="height:40px;">
                </p>
-->
                <p align="center">
                    <font size="3">nick.antipa@eecs.berkeley.edu </font>&nbsp;|&nbsp;
                     <a href="./antipa_files/Nick_CV.pdf">Curriculum Vitae</a> &nbsp;|&nbsp;
                    <!-- <a href="http://github.com/antipa">Github</a> &nbsp;|&nbsp; --> 
                    <a href="https://scholar.google.com/citations?user=15xSd1gAAAAJ&hl=en">Google Scholar</a>
                </p>
                   
                <p>
                    <strong>I am thrilled to announce that, starting in January 2021, I will be joining the faculty at the UC San Diego Jacobs School of Engineering in the department of Electrical and Computer Engineering! </strong>
                </p>
                
                <p>
                About me: I am finishing up my PhD at UC Berkeley where I study Computational Imaging with Laura Waller and Ren Ng. Prior to my PhD work, I spent 5 years working on optical metrology for the National Ignition Facility at Lawrence Livermore National Lab. When I'm not working, I like hiking and playing the trumpet. 
                </p>

<!--            </td>-->
            </div>
            <div class="column_onefifth">
<!--            <td width="5%">-->
            <!-- <img src="topics/portrait_circle.jpg"> -->
                <br><br>
            <img src="./antipa_files/headshot_crop.jpg" style="width:200px;">

            </div>
<!--            </td>-->
        </div>
<!--        </tr>-->
    </tbody>
</table>
        




   
        <table width="62.5%" align="middle" border="0" cellspacing="0" cellpadding="20">
            <heading>Research interests</heading>
            <hr>
          <tbody><tr>
            <td width="100%" valign="middle">
              <tr width="100%" valign="middle">
              <p>
                  I am broadly interested in design of computational imaging systems that capture more than just 2D. By jointly designing optics, sensors, and algorithms, I aim to discover novel imaging systems that enable modalities not possible with conventional lenses and sensors alone. 
                  
                <br>
                  <br>
                  Most of my work has focused on single-shot capture of high dimensional optical signals. Inspired by compressed sensing, I have spent my PhD time researching pseudorandom phase optics (i.e. diffusers) as a computational imaging element capable of snapshot capture of high dimensional optical signals. When added to the focal plane of a conventional camera, a <a href="#LightField">diffuser encodes 4D light field</a> information, allowing recovery via optimization methods. Additionally, as shown in our work on the <a href="https://waller-lab.github.io/DiffuserCam/index.html">DiffuserCam</a> (coauthored with <a href="https://people.eecs.berkeley.edu/~gkuo/">Grace Kuo</a>), the diffuser can simultaneously act as the imaging element and the high-dimensional encoder. This lensless architecture is capable of encoding 3D signals, such as <a href="#DiffuserCam">volumetric</a> and <a href="#rolling_shutter">video data</a>, into a single snapshot measurement. Using sparse recovery methods inspired by compressed sensing, sparse high dimensional signals can be recovered with far more samples than sensor pixels. 
                  <br><br>
                 Please see the <a href="https://waller-lab.github.io/DiffuserCam/index.html">DiffuserCam project page for more information</a>, including a tutorial to <a href="https://waller-lab.github.io/DiffuserCam/quickstart.html">build your own</a> using a Raspberry Pi, put together by <a href="https://www.linkedin.com/in/shreyasparth/">Shreyas Parthasarathy</a> and <a href="https://www.csail.mit.edu/person/camille-biscarrat">Camille Biscarrat</a>.
                  
              </p>
                </tr>
            </td>
          </tr>
        </tbody></table>
          
    

<heading>Recent projects</heading>
<hr>
            

        
  <!------------------------Miniscope--------------------------- -->     
          
          

          
  <a name="Miniscope"></a>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" white-space:wrap>

          <tbody>
              
              
            <tr width="100%" valign="middle">
             
                

                  <papertitle>3D Miniscope, aka Randoscope</papertitle>
                This uses a new custom design based on the architecture shown at <a href="https://www.osapublishing.org/viewmedia.cfm?r=1&uri=BRAIN-2019-BT3A.4&seq=0">OSA Biophotonics 2019.</a>
                   


                    
                 


                    <br>

                  

                <p><strong>New results from our snapshot 3D fluorescent miniscope, Randoscope!</strong> This system combines the DiffuserCam with the <a href="http://miniscope.org/index.php/Main_Page">Miniscope</a>, replacing the tube lens with an engineered diffuser prototyped using multiphoton polymerization. The result is an inexpensive compressive imaging system that can capture fluorescent volumes with 3 micron lateral resolution and 10 micron axial at video rates with no moving parts. This compact system is well suited to a range of applications where inexpensive, compact volumetric fluorescence imaging is needed. This could range from parallel imaging in incubators where space is an issue, to head-mounting for volumetric in-vivo neuroscience. 
                 <br>
                    <br>
                The videos below show the snapshot 3D reconstruction capability of this system. The first is a time series of a fluorescence-stained tardigrade (waterbear) acquired at 30 volumes/second. Below that is a snapshot reconstruction of neurons expressing GFP in cleared mouse brain tissue. Our system achieves a far greater axial imaging range than conventional light field approaches. </p>
            </tr>
              

                
                
<!--            <tr>-->
              <div class="row">
<!--                <td valign="top" width="45%">-->
                  <div class="column_onethird">
                        <br>
                        <br>
                        <br>
                        <br><br>
                      <img  src="./antipa_files/miniscope_with_quarter_drawing.png" style="width:250px">
                  </div>
<!--                </td>-->
<!--                <td>-->
                  <div class="column">
                    <img id="gif-bears" src="./antipa_files/waterbear4_parula_combined.gif" style="width:600px">
                </div>
<!--                </td>-->
              </div>
              <div class="row">
                  <div class="column">
                      
                      <img  src="./antipa_files/neurons_raw.png" style="width:500px">
                      <br>
                      Single frame raw data, cleared mouse brain neurons expressing GFP
                  </div>

                  <div class="column">
                    
                    <img id="gif-neurons" src="./antipa_files/neurons.gif" style="width:490px">
                      <br>
                      Volumetric reconstruction showing individual neuron cell bodies and dendrites, 900x700x300 micron (WxHxD).
                </div>

              </div>

        </tbody>
        </table>
          
          <hr>
          
          
          
  <!--------------------------Rolling Shutter---------------------------       -->
          
          
          
  <a name="rolling_shutter"></a>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" white-space:wrap>

          <tbody>
              
              
            <tr width="100%" valign="middle">
             
                

                  <a href="https://ieeexplore.ieee.org/abstract/document/8747341">  <papertitle>Video from Stills: Lensless Imaging with Rolling    Shutter</papertitle>
                    </a>


                    <a href="https://arxiv.org/abs/1905.13221"><papertitle>[arXiv]</papertitle></a>
                    
                    <br><br>
                    <a href="antipa_files/hsvideo_code_with_data.zip"><papertitle>[Code and sample data]</papertitle></a>
                    <br><br>
                    <br>

                    <strong>Nick Antipa*</strong>, <a> Patrick Oare*</a>,
                  <a href="https://emrahbostan.com/">Emrah Bostan</a>,
                  <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>,
                  <a href="http://www.laurawaller.com/">Laura Waller</a>
                  <br>
                  <em>IEEE International Conference on Computational Photography (ICCP)</em>, 2019.
                  <br>
                    <strong><font color="#e60008">Best paper at ICCP 2019</font></strong>
                    <br>

                  <p>This project demonstrates the innate compressive video properties of DiffuserCam. Because image sensor chips have a finite bandwidth with which to read out pixels, recording video typically requires a trade-off between frame rate and pixel count. Compressed sensing techniques can circumvent this trade-off by assuming that the image is compressible. Here, we propose using multiplexing optics to spatially compress the scene, enabling information about the whole scene to be sampled from a row of sensor pixels, which can be read off quickly via a rolling shutter CMOS sensor. Conveniently, such multiplexing can be achieved with a simple lensless, diffuser-based imaging system. Using sparse recovery methods, we are able to recover 140 video frames at over 4,500 frames per second, all from a single captured image with a rolling shutter sensor. Our proof-of-concept system uses easily-fabricated diffusers paired with an off-the-shelf sensor. The resulting prototype enables compressive encoding of high frame rate video into a single rolling shutter exposure, and exceeds the sampling-limited performance of an equivalent global shutter system for sufficiently sparse objects.</p>
            </tr>
              

                
                
            <div class="row">
<!--                <td valign="top" width="45%">-->
                <div class="column_full">
                    <img  src="./antipa_files/rolling_shutter_schematic.png" style="width:320px">
                    <img src="./antipa_files/dart_apple_raw4web.png" style = "width:320px">
                    <img src="./antipa_files/dart_apple_220_1320us_270x320_gifbrew.gif" style = "width:320px">
                </div>
<!--
                <div class="column_twothirds">
                    <img src="./antipa_files/dart_apple_raw4web.png" style = "width:320px">
                    <img src="./antipa_files/dart_apple_220_1320us_270x320_gifbrew.gif" style = "width:320px">
                </div>
-->
<!--
                <div class="column">
                    <img src="./antipa_files/dart_apple_220_1320us_270x320_gifbrew.gif" style = "width:320px">
                </div>
-->
<!--                </td>-->
                
<!--
                <td>
                    <div class="one">
                        <img id="gif-2" src="./antipa_files/dart_apple_raw4web.png" style="width:320px"
                             onmouseover="document.getElementById('gif-2').src='./antipa_files/dart_apple_220_1320us_270x320_gifbrew.gif'"
                             onmouseout="document.getElementById('gif-2').src='./antipa_files/dart_apple_raw4web.png'"
                             />
                    <h2><font color="White">Hover to see reconstruction</font></h2>
                        <h4><font color="Black">This entire video is computed from a single sensor exposure!</h4>
                    </div>
                </td>
-->
<!--            </tr>-->
              </div>
<!--
              <div class="row">
                  <iframe src="https://widgets.figshare.com/articles/7961138/embed?show_title=1" width="568" height="351" allowfullscreen="true" frameborder="0"></iframe>
              </div>
-->
        </tbody>
        </table>
          
          <hr>
          
          
<!--------------------------DiffuserCam---------------------------       -->
          
          
<a name="DiffuserCam"></a>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" white-space:wrap>

          <tbody>
              
              
            <tr width="100%" valign="middle">
             
                

                  <a href="https://www.osapublishing.org/optica/abstract.cfm?uri=optica-5-1-1">  <papertitle>DiffuserCam: lensless single-exposure 3D imaging</papertitle>
                    </a>


                    <a href="https://arxiv.org/abs/1710.02134"><papertitle>[arXiv]</papertitle></a>


                    <br>

                    <strong>Nick Antipa*</strong>, <a href="https://people.eecs.berkeley.edu/~gkuo/">Grace Kuo*</a>, <a>Reinhard Heckel, Ben Mildenhall,</a>
                  <a href="https://emrahbostan.com/">Emrah Bostan</a>,
                  <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>,
                  <a href="http://www.laurawaller.com/">Laura Waller</a>
                  <br>
                  <em>Optica</em>, 2018.
                  <br>
                    <strong><font color="#e60008">No. 2 in Optica 15 top-cited articles, Jan 2020</font></strong>
                   <br>
                <br>
                    <strong><font color="#e60008">Best demo, ICCP 2017</font></strong>
                   <br>

          
                
                    

                  <p>We demonstrate a compact, easy-to-build computational camera for single-shot three-dimensional (3D) imaging. Our lensless system consists solely of a diffuser placed in front of an image sensor. Every point within the volumetric field-of-view projects a unique pseudorandom pattern of caustics on the sensor. By using a physical approximation and simple calibration scheme, we solve the large-scale inverse problem in a computationally efficient way. The caustic patterns enable compressed sensing, which exploits sparsity in the sample to solve for more 3D voxels than pixels on the 2D sensor. Our 3D reconstruction grid is chosen to match the experimentally measured two-point optical resolution, resulting in 100 million voxels being reconstructed from a single 1.3 megapixel image. However, the effective resolution varies significantly with scene content. Because this effect is common to a wide range of computational cameras, we provide a new theory for analyzing resolution in such systems.</p>
            </tr>
              

                
                
<!--
            <tr>
                <td valign="top" width="45%">
                  <img  src="./antipa_files/3d_shift_animation.gif" style="width:453px">
                </td>
                <td>
                    <div class="one">
                        <img id="gif-3" src="./antipa_files/fern_for_web_4x.png" style="width:640px"
                             
                             onmouseover="document.getElementById('gif-3').src='./antipa_files/fern_anim_highres_for_web.gif'"
                             onmouseout="document.getElementById('gif-3').src='./antipa_files/fern_for_web_4x.png'"
                             />
                        <h2>
                            <font color="White">Hover to see reconstructions</font>
                        </h2>
                        
                    </div>
                </td>
            </tr>
--> 
              <div class="row">
                  <div class="column_full">
                      <img  src="./antipa_files/3d_shift_animation.gif" style="width:320px">
                      <img  src="./antipa_files/fern_for_web_4x.png" style="width:320px">
                      <img  src="./antipa_files/fern_anim_highres_for_web.gif" style="width:320px">
                  </div>
              </div>
        </tbody>
        </table>
          
      
          
             
          <hr>       
          
          
<!--------------------------Light Field---------------------------       -->
          
          
          
          
          
<a name='LightField'></a>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" white-space:wrap>

      <tbody>
              
              
        <tr width="100%" valign="middle">



              <a href="https://ieeexplore.ieee.org/document/7492880">  <papertitle>Single-shot diffuser-encoded light field imaging</papertitle>
                </a>
                <br>

                <strong>Nick Antipa*</strong>, <a>Sylvia Necula</a>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>,
            <a href="http://www.laurawaller.com/">Laura Waller</a>
            <br>
                <em>IEEE International Conference on Computational Photography (ICCP)</em>, 2016.
            <br>
                <strong><font color="#e60008">Best paper at ICCP 2016</font></strong>
            <br>


              <p>We capture 4D light field data in a single 2D sensor image by encoding spatio-angular information into a speckle field (caustic pattern) through a phase diffuser. Using wave-optics theory and a coherent phase retrieval method, we calibrate the system by measuring the diffuser surface height from through-focus images. Wave-optics theory further informs the design of system geometry such that a purely additive ray-optics model is valid. Light field reconstruction is done using sparsity-constrained iterative inverse methods. We demonstrate a prototype system and present empirical results of 4D light field reconstruction and computational refocusing from a single diffuser-encoded 2D image.</p>
        </tr>




        <div class="row">
          
<!--            <td valign="top" width="65%">-->
            <div class="column">
              <img  src="./antipa_files/lf_diagram.png" style="width:320px">
            </div>
            <div class="column_onethird">
                 <div class="one">
                        <div>
                             <font color="Black">Refocusable 4D light field</font><br/>
                            <img src="./antipa_files/lf_gif.gif" style="width:200px"/>
                        </div>
                       
<!--                        <h2><font color="White">Hover to see reconstruction</font></h2>-->
                        
                        <br/>
                        <br/>
                        <br/>
                        <div>
                            <font color="Black">spatio-angular image</font><br/>
                            <img src="./antipa_files/lf_epi.png" style="width:200px"/>
                        </div>
                        
<!--
                        <h3>
                            <font color="Black">refocusable light field</font>
                        </h3>
-->
                        
                    </div>
            </div>
<!--            </td>-->

<!--
                <div class="one">
                    <img id="gif-4" src="./antipa_files/fern_for_web_4x.png" style="width:640px"

                         onmouseover="document.getElementById('gif-4').src='./antipa_files/fern_anim_highres_for_web.gif'"
                         onmouseout="document.getElementById('gif-4').src='./antipa_files/fern_for_web_4x.png'"
                         />
                    <h2>
                        <font color="White">Hover to see reconstructions</font>
                    </h2>

                </div>

--> 
            
<!--
            <td>
                    <div class="one">
                        <font color="Black">Refocusable 4D light field</font>
                        <img src="./antipa_files/lf_gif.gif" style="width:300px"/>
                        
                        
                        <br/>
                        <br/>
                        <br/>
                        <font color="Black">spatio-angular image</font>
                        <img src="./antipa_files/lf_epi.png" style="width:300px"/>
                        <h3>
                            <font color="Black">refocusable light field</font>
                        </h3>
                        
                    </div>
            </td>
-->
<!--
            <td valign="top" width="15%">
                <div class="one">
                    <img src="./antipa_files/lf_gif.gif" style="width:350px">
              
                    <img src="./antipa_files/lf_epi.png" style="width:350px">
                     <h2>
                        <font color="Red">Refocusable light field</font>
                     </h2>
                </div>
              
                
            </td>
-->
            
        </div>
    </tbody>
</table>

<!--        </div>-->
                      


          
<!--
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody>
            <tr>
                <td width="100%" valign="middle">
                <heading>This is some youtube thing</heading>
                </td>
            </tr>
            
        </tbody>
        </table>
-->
            

            
                    
      
          
        






        
<hr>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
<tbody><tr>
<td width="100%" valign="center">
<center> 
  Copyright 2020 Nick Antipa. All rights reserved.
</center>
<br>
    
</td>
</tr>
</tbody></table>

    <!--                class="firstLine" onmouseout="portrait_stop2()" onmouseover="portrait_start2()" valign="top" width="50%">-->
<!--                <tr class="firstLine" onmouseout="portrait_stop2()" onmouseover="portrait_start2()">-->
<!--
                <div class="one">

                    <div class="two" id="portrait_image2" style="opacity: 0;">
                        <img  src="./antipa_files/dart_apple_220_1320us_540_640.gif" style="width:640px">
                    </div>

                    <img src="./antipa_files/dart_apple_raw4web.png" style="width:640px">
                    <h2><font color="White">Hover to see reconstructions</font></h2>

                </div>
-->             



<!--
                <script type="text/javascript">
                function portrait_start2() {
                  document.getElementById('portrait_image2').style.opacity = "1";
                }

                function portrait_stop2() {
                  document.getElementById('portrait_image2').style.opacity = "0";
                }
                portrait_stop2()
                </script>
-->         



</td></tr></tbody></table></div></body></html>
